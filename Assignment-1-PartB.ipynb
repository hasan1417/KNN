{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)--PartB\n",
    "## Breast cancer wisconsin dataset\n",
    "In this assignment, we will build a KNN classifier that takes an features as as input and outputs a label 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset contains 569 samples with 30 real, positive features (including cancer mass attributes like mean radius, mean texture, mean perimeter, et cetera). Of the samples, 212 are labeled “malignant” and 357 are labeled “benign”. \n",
    "You can find more details in: https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "## Load the training set\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 569\n",
      "Number of features per sample: 30\n",
      "Total number of classes: 2\n",
      "Number of samples in each class:\n",
      "  malignant: 212\n",
      "  benign: 357\n"
     ]
    }
   ],
   "source": [
    "## print some statistics on the dataset\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "print(\"Total number of samples:\", X.shape[0])\n",
    "\n",
    "print(\"Number of features per sample:\", X.shape[1])\n",
    "\n",
    "print(\"Total number of classes:\", len(data.target_names))\n",
    "\n",
    "print(\"Number of samples in each class:\")\n",
    "for i, class_name in enumerate(data.target_names):\n",
    "    print(f\"  {class_name}: {sum(y == i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 398 samples\n",
      "Validation set size: 85 samples\n",
      "Test set size: 86 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### TODO YOUR CODE ###\n",
    "# Set random seed\n",
    "random_seed = 777\n",
    "\n",
    "# Split into training set (70%) and temporary set (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "\n",
    "# Split the temporary set into validation set (15%) and test set (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "# Verify the sizes of each set\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification with L2 distance\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. A natural distance function is _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Often we omit the square root, and simply compute _squared Euclidean distance_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`evalx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NN_L2(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predictions = []\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for eval_point in evalx:\n",
    "        # Calculate the L2 (Euclidean) distance between the eval_point and all training points\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point)**2, axis=1))\n",
    "        \n",
    "        # Find the index of the nearest neighbor (smallest distance)\n",
    "        nearest_neighbor_idx = np.argmin(distances)\n",
    "        \n",
    "        # Get the label of the nearest neighbor and append it to predictions\n",
    "        predictions.append(trainy[nearest_neighbor_idx])\n",
    "    \n",
    "    # Convert predictions list to a numpy array and return\n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L2**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "        # Initialize an empty list to store the predictions\n",
    "    predictions = []\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for eval_point in evalx:\n",
    "        # Calculate the L2 (Euclidean) distance between the eval_point and all training points\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point)**2, axis=1))\n",
    "        \n",
    "        # Find the indices of the K nearest neighbors\n",
    "        nearest_neighbor_idxs = np.argsort(distances)[:K]\n",
    "        \n",
    "        # Get the labels of the K nearest neighbors\n",
    "        nearest_neighbor_labels = trainy[nearest_neighbor_idxs]\n",
    "        \n",
    "        # Predict the label by taking the most common label among the nearest neighbors\n",
    "        most_common_label = Counter(nearest_neighbor_labels).most_common(1)[0][0]\n",
    "        \n",
    "        # Append the predicted label to the predictions list\n",
    "        predictions.append(most_common_label)\n",
    "    \n",
    "    # Convert predictions list to a numpy array and return\n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `evalx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L1(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L1**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification and L1 distance metric. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "        predictions = []\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for eval_point in evalx:\n",
    "        # Calculate the L1 (Manhattan) distance between the eval_point and all training points\n",
    "        distances = np.sum(np.abs(trainx - eval_point), axis=1)\n",
    "        \n",
    "        # Find the index of the nearest neighbor (smallest distance)\n",
    "        nearest_neighbor_idx = np.argmin(distances)\n",
    "        \n",
    "        # Get the label of the nearest neighbor and append it to predictions\n",
    "        predictions.append(trainy[nearest_neighbor_idx])\n",
    "    \n",
    "    # Convert predictions list to a numpy array and return\n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), the value of **K** (integer), and a parameter for deciding the distance metric to be used (for example 1 for L1 and 2 for L2) and predicts labels for these test points using KNN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predictions = np.empty(evalx.shape[0], dtype=int)\n",
    "    \n",
    "    if dist_metric == 1:\n",
    "        # L1 (Manhattan) Distance\n",
    "        # Calculate all distances in a vectorized way\n",
    "        distances = np.sum(np.abs(trainx[np.newaxis, :] - evalx[:, np.newaxis]), axis=2)\n",
    "    elif dist_metric == 2:\n",
    "        # L2 (Euclidean) Distance\n",
    "        # Calculate all distances in a vectorized way\n",
    "        distances = np.sqrt(np.sum((trainx[np.newaxis, :] - evalx[:, np.newaxis])**2, axis=2))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric! Use 1 for L1 and 2 for L2.\")\n",
    "    \n",
    "    # Find the indices of the K nearest neighbors for each evaluation point\n",
    "    nearest_neighbor_idxs = np.argsort(distances, axis=1)[:, :K]\n",
    "    \n",
    "    # Use fancy indexing to get the labels of the K nearest neighbors\n",
    "    nearest_neighbor_labels = trainy[nearest_neighbor_idxs]\n",
    "    \n",
    "    # For each evaluation point, find the most common label among the K neighbors using numpy functions\n",
    "    for i in range(evalx.shape[0]):\n",
    "        labels, counts = np.unique(nearest_neighbor_labels[i], return_counts=True)\n",
    "        most_common_label = labels[np.argmax(counts)]\n",
    "        predictions[i] = most_common_label\n",
    "    \n",
    "    return predictions\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that allows you to select the hyper-parameters (distance measure and the value of K) by calling the KNN classifier with different values of K and either L1 or L2 distance measure. Make sure that you set the hyper-parameters using the validation set and not the test set. You need to systemtically try different values for K in conjunction with a distance measure and tabulate the results (you can do that be craeting a seperate cell and documenting in that cell) and note down the best hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 6\n",
      "Best Distance Metric: L1\n",
      "Best Validation Accuracy: 0.9647\n",
      "\n",
      "Results for all K and distance metrics combinations:\n",
      "K: 1, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 1, Distance Metric: L2, Validation Accuracy: 0.8941\n",
      "K: 2, Distance Metric: L1, Validation Accuracy: 0.9294\n",
      "K: 2, Distance Metric: L2, Validation Accuracy: 0.9059\n",
      "K: 3, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 3, Distance Metric: L2, Validation Accuracy: 0.9412\n",
      "K: 4, Distance Metric: L1, Validation Accuracy: 0.9529\n",
      "K: 4, Distance Metric: L2, Validation Accuracy: 0.9412\n",
      "K: 5, Distance Metric: L1, Validation Accuracy: 0.9529\n",
      "K: 5, Distance Metric: L2, Validation Accuracy: 0.9294\n",
      "K: 6, Distance Metric: L1, Validation Accuracy: 0.9647\n",
      "K: 6, Distance Metric: L2, Validation Accuracy: 0.9294\n",
      "K: 7, Distance Metric: L1, Validation Accuracy: 0.9412\n",
      "K: 7, Distance Metric: L2, Validation Accuracy: 0.9294\n",
      "K: 8, Distance Metric: L1, Validation Accuracy: 0.9529\n",
      "K: 8, Distance Metric: L2, Validation Accuracy: 0.9412\n",
      "K: 9, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 9, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 10, Distance Metric: L1, Validation Accuracy: 0.9294\n",
      "K: 10, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 11, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 11, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 12, Distance Metric: L1, Validation Accuracy: 0.9294\n",
      "K: 12, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 13, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 13, Distance Metric: L2, Validation Accuracy: 0.9059\n",
      "K: 14, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 14, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 15, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 15, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 16, Distance Metric: L1, Validation Accuracy: 0.9176\n",
      "K: 16, Distance Metric: L2, Validation Accuracy: 0.9176\n",
      "K: 17, Distance Metric: L1, Validation Accuracy: 0.8941\n",
      "K: 17, Distance Metric: L2, Validation Accuracy: 0.9059\n",
      "K: 18, Distance Metric: L1, Validation Accuracy: 0.9059\n",
      "K: 18, Distance Metric: L2, Validation Accuracy: 0.9059\n",
      "K: 19, Distance Metric: L1, Validation Accuracy: 0.9059\n",
      "K: 19, Distance Metric: L2, Validation Accuracy: 0.8824\n",
      "K: 20, Distance Metric: L1, Validation Accuracy: 0.9059\n",
      "K: 20, Distance Metric: L2, Validation Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Now, use the code to perform hyper-parameter tuning\n",
    "# Define the range of K values to test\n",
    "k_values = range(1, 21)  # Testing K values from 1 to 20\n",
    "\n",
    "# Define the distance metrics to test\n",
    "distance_metrics = [1, 2]  # 1 for L1, 2 for L2\n",
    "\n",
    "# Variables to store the best hyper-parameters and their corresponding accuracy\n",
    "best_k = None\n",
    "best_dist_metric = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Dictionary to store results for documentation\n",
    "results = {}\n",
    "\n",
    "# Iterate over all combinations of K and distance metrics\n",
    "for k in k_values:\n",
    "    for dist_metric in distance_metrics:\n",
    "        # Predict on the validation set using the current combination of K and distance metric\n",
    "        val_predictions = KNN(X_train, y_train, X_val, k, dist_metric)\n",
    "        \n",
    "        # Calculate the accuracy on the validation set\n",
    "        val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "        \n",
    "        # Store the result\n",
    "        results[(k, dist_metric)] = val_accuracy\n",
    "        \n",
    "        # Update best parameters if the current accuracy is better\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_k = k\n",
    "            best_dist_metric = dist_metric\n",
    "\n",
    "# Print the best hyper-parameters and their corresponding accuracy\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Distance Metric: {'L1' if best_dist_metric == 1 else 'L2'}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Print the tabulated results for reference\n",
    "print(\"\\nResults for all K and distance metrics combinations:\")\n",
    "for (k, dist_metric), accuracy in results.items():\n",
    "    print(f\"K: {k}, Distance Metric: {'L1' if dist_metric == 1 else 'L2'}, Validation Accuracy: {accuracy:.4f}\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the hyper-parameters have been selected, we now would like to perform a final evaluation on the test set and record the error rates. Also, Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array`.\n",
    "\n",
    "**Note:** Record the cpu time it takes to perform the evaluation on the test set using functions like **time.time()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def confusion(testy, testy_fit):\n",
    "    # inputs: the correct labels, the fitted KNN labels \n",
    "    # output: a 10x10 np.array representing the confusion matrix as above\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return confusion_matrix(testy, testy_fit)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.0080 seconds\n",
      "Test Error Rate: 0.0349\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  3]\n",
      " [ 0 57]]\n"
     ]
    }
   ],
   "source": [
    "# Code for performing the final evaluation on the test set and generating the confuson matrix.\n",
    "### START CODE HERE ###\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "# Predict on the test set using the best K and distance metric\n",
    "test_predictions = KNN(X_train, y_train, X_test, best_k, best_dist_metric)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "evaluation_time = end_time - start_time  # Calculate evaluation time\n",
    "\n",
    "# Calculate the error rate\n",
    "error_rate = 1 - accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Evaluation Time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Test Error Rate: {error_rate:.4f}\")\n",
    "\n",
    "# Get the confusion matrix for the test set\n",
    "conf_matrix = confusion(y_test, test_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preparing the assignment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to record your answers for the following questions:\n",
    "1. What is the error rate on the validation set for NN_L2?\n",
    "2. What is the best error rate on the validation set for KNN_L2?\n",
    "3. What is the error rate on the validation set for NN_L1?\n",
    "4. What is the best error rate on the validation set for KNN_L1?\n",
    "5. What is the error rate on the test set?\n",
    "7. Do you need to normalize data, in general, when using KNN?\n",
    "8. Do you need to normalize data when using KNN for the given problem? Explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Implementing weighted KNN where the vote of a neighbour is scaled down based on its distance from the test point.\n",
    "2. Implement L_infinity distance measure and use it for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    # inputs: \n",
    "    # trainx (training features), \n",
    "    # trainy (training labels), \n",
    "    # evalx (evaluation features), \n",
    "    # K (number of neighbors), \n",
    "    # dist_metric (1 for L1, 2 for L2)\n",
    "    \n",
    "    predictions = np.empty(evalx.shape[0], dtype=int)\n",
    "    \n",
    "    if dist_metric == 1:\n",
    "        distances = np.sum(np.abs(trainx[np.newaxis, :] - evalx[:, np.newaxis]), axis=2)\n",
    "    elif dist_metric == 2:\n",
    "        distances = np.sqrt(np.sum((trainx[np.newaxis, :] - evalx[:, np.newaxis])**2, axis=2))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric! Use 1 for L1 and 2 for L2.\")\n",
    "    \n",
    "    for i in range(evalx.shape[0]):\n",
    "        # Find the indices of the K nearest neighbors\n",
    "        nearest_neighbor_idxs = np.argsort(distances[i])[:K]\n",
    "        \n",
    "        # Get the distances of the K nearest neighbors\n",
    "        nearest_distances = distances[i][nearest_neighbor_idxs]\n",
    "        \n",
    "        # Calculate the weights (inverse of the distances)\n",
    "        weights = 1 / (nearest_distances + 1e-5)  # Add a small value to avoid division by zero\n",
    "        \n",
    "        # Get the labels of the K nearest neighbors\n",
    "        nearest_labels = trainy[nearest_neighbor_idxs]\n",
    "        \n",
    "        # Calculate the weighted votes\n",
    "        unique_labels = np.unique(nearest_labels)\n",
    "        weighted_votes = np.zeros(len(unique_labels))\n",
    "        \n",
    "        for idx, label in enumerate(unique_labels):\n",
    "            label_weights = weights[nearest_labels == label]\n",
    "            weighted_votes[idx] = np.sum(label_weights)\n",
    "        \n",
    "        # Predict the label with the maximum weighted vote\n",
    "        predictions[i] = unique_labels[np.argmax(weighted_votes)]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for Weighted KNN (K=5, L2): 0.9294\n",
      "Validation Accuracy for Weighted KNN (K=5, L1): 0.9529\n"
     ]
    }
   ],
   "source": [
    "weighted_predictions = weighted_KNN(X_train, y_train, X_val, K=5, dist_metric=2)\n",
    "weighted_val_accuracy = accuracy_score(y_val, weighted_predictions)\n",
    "print(f\"Validation Accuracy for Weighted KNN (K=5, L2): {weighted_val_accuracy:.4f}\")\n",
    "\n",
    "# Test Weighted KNN with K=5 and L1 distance\n",
    "weighted_predictions_l1 = weighted_KNN(X_train, y_train, X_val, K=5, dist_metric=1)\n",
    "weighted_val_accuracy_l1 = accuracy_score(y_val, weighted_predictions_l1)\n",
    "print(f\"Validation Accuracy for Weighted KNN (K=5, L1): {weighted_val_accuracy_l1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Weighted KNN (K=5, L1): 0.9302\n",
      "\n",
      "Confusion Matrix for Test Set (Weighted KNN, K=5, L1):\n",
      "[[23  6]\n",
      " [ 0 57]]\n"
     ]
    }
   ],
   "source": [
    "# Assume the best model is Weighted KNN with K=5 and L2\n",
    "# Test on the test set\n",
    "weighted_test_predictions = weighted_KNN(X_train, y_train, X_test, K=5, dist_metric=1)\n",
    "weighted_test_accuracy = accuracy_score(y_test, weighted_test_predictions)\n",
    "print(f\"Test Accuracy for Weighted KNN (K=5, L1): {weighted_test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the test set\n",
    "conf_matrix_test = confusion(y_test, weighted_test_predictions)\n",
    "print(\"\\nConfusion Matrix for Test Set (Weighted KNN, K=5, L1):\")\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L_infinity(trainx, trainy, evalx, K):\n",
    "    # inputs: \n",
    "    # trainx (training features), \n",
    "    # trainy (training labels), \n",
    "    # evalx (evaluation features), \n",
    "    # K (number of neighbors)\n",
    "    \n",
    "    # Initialize an empty array to store the predictions\n",
    "    predictions = np.empty(evalx.shape[0], dtype=int)\n",
    "    \n",
    "    # Calculate L-infinity (Chebyshev) distance between each eval point and all train points\n",
    "    distances = np.max(np.abs(trainx[np.newaxis, :] - evalx[:, np.newaxis]), axis=2)\n",
    "    \n",
    "    # Find the indices of the K nearest neighbors for each evaluation point\n",
    "    nearest_neighbor_idxs = np.argsort(distances, axis=1)[:, :K]\n",
    "    \n",
    "    # Use fancy indexing to get the labels of the K nearest neighbors\n",
    "    nearest_neighbor_labels = trainy[nearest_neighbor_idxs]\n",
    "    \n",
    "    # For each evaluation point, find the most common label among the K neighbors using numpy functions\n",
    "    for i in range(evalx.shape[0]):\n",
    "        labels, counts = np.unique(nearest_neighbor_labels[i], return_counts=True)\n",
    "        most_common_label = labels[np.argmax(counts)]\n",
    "        predictions[i] = most_common_label\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for KNN with L-infinity (K=5): 0.9294\n"
     ]
    }
   ],
   "source": [
    "# Test L-infinity KNN with K=5\n",
    "linfinity_predictions = KNN_L_infinity(X_train, y_train, X_val, K=5)\n",
    "linfinity_val_accuracy = accuracy_score(y_val, linfinity_predictions)\n",
    "print(f\"Validation Accuracy for KNN with L-infinity (K=5): {linfinity_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for KNN with L-infinity (K=5): 0.9186\n",
      "\n",
      "Confusion Matrix for Test Set (KNN with L-infinity, K=5):\n",
      "[[24  5]\n",
      " [ 2 55]]\n"
     ]
    }
   ],
   "source": [
    "K_best = 5\n",
    "\n",
    "# Test KNN with L-infinity distance on the test set\n",
    "linfinity_test_predictions = KNN_L_infinity(X_train, y_train, X_test, K=K_best)\n",
    "linfinity_test_accuracy = accuracy_score(y_test, linfinity_test_predictions)\n",
    "print(f\"Test Accuracy for KNN with L-infinity (K={K_best}): {linfinity_test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the test set\n",
    "conf_matrix_test_linfinity = confusion(y_test, linfinity_test_predictions)\n",
    "print(\"\\nConfusion Matrix for Test Set (KNN with L-infinity, K=5):\")\n",
    "print(conf_matrix_test_linfinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. \n",
    "2. Vectorize the code wherever possible instead of using explicit loops. This will significantly speed-up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
