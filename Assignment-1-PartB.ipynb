{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)--PartB\n",
    "## Breast cancer wisconsin dataset\n",
    "In this assignment, we will build a KNN classifier that takes an features as as input and outputs a label 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset contains 569 samples with 30 real, positive features (including cancer mass attributes like mean radius, mean texture, mean perimeter, et cetera). Of the samples, 212 are labeled “malignant” and 357 are labeled “benign”. \n",
    "You can find more details in: https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 569\n",
      "Number of features per sample: 30\n",
      "Total number of classes: 2\n",
      "Number of samples in each class:\n",
      "  malignant: 212\n",
      "  benign: 357\n"
     ]
    }
   ],
   "source": [
    "## print some statistics on the dataset\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "print(\"Total number of samples:\", X.shape[0])\n",
    "\n",
    "print(\"Number of features per sample:\", X.shape[1])\n",
    "\n",
    "print(\"Total number of classes:\", len(data.target_names))\n",
    "\n",
    "print(\"Number of samples in each class:\")\n",
    "for i, class_name in enumerate(data.target_names):\n",
    "    print(f\"  {class_name}: {sum(y == i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 398 samples\n",
      "Validation set size: 85 samples\n",
      "Test set size: 86 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### TODO YOUR CODE ###\n",
    "# Set random seed\n",
    "random_seed = 777\n",
    "\n",
    "# Split into training set (70%) and temporary set (test and validation) (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "\n",
    "# Split the temporary set into validation set (15%) and test set (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "# Verify the sizes of each set\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the validation and test sets (without fitting again)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test= scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification with L2 distance\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. A natural distance function is _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Often we omit the square root, and simply compute _squared Euclidean distance_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`evalx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L2(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predictions = []\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for eval_point in evalx:\n",
    "        # Calculate the L2 (Euclidean) distance between the eval_point and all training points\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point)**2, axis=1))\n",
    "        \n",
    "        # Find the index of the nearest neighbor (smallest distance)\n",
    "        nearest_neighbor_idx = np.argmin(distances)\n",
    "        \n",
    "        # Get the label of the nearest neighbor and append it to predictions\n",
    "        predictions.append(trainy[nearest_neighbor_idx])\n",
    "    \n",
    "    # Convert predictions list to a numpy array and return\n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L2**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for evalx \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize an empty array to store the predictions\n",
    "    predictions = np.empty(evalx.shape[0], dtype=trainy.dtype)\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for i, eval_point in enumerate(evalx):\n",
    "        # Calculate the L2 (Euclidean) distance between the eval_point and all training points\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point)**2, axis=1))\n",
    "        \n",
    "        # Find the indices of the K nearest neighbors\n",
    "        nearest_neighbor_idxs = np.argsort(distances)[:K]\n",
    "        \n",
    "        # Get the labels of the K nearest neighbors\n",
    "        nearest_neighbor_labels = trainy[nearest_neighbor_idxs]\n",
    "        \n",
    "        # Predict the label by taking the most common label among the nearest neighbors\n",
    "        unique_labels, label_counts = np.unique(nearest_neighbor_labels, return_counts=True)\n",
    "        most_common_label = unique_labels[np.argmax(label_counts)]\n",
    "        \n",
    "        # Store the predicted label in the predictions array\n",
    "        predictions[i] = most_common_label\n",
    "    \n",
    "    return predictions\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `evalx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L1(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    # Get the number of test points\n",
    "    n_test = evalx.shape[0]\n",
    "    \n",
    "    # Initialize an array to store predictions\n",
    "    predictions = np.zeros(n_test, dtype=trainy.dtype)\n",
    "    \n",
    "    # Iterate through each test point\n",
    "    for i in range(n_test):\n",
    "        # Compute L1 distances between the test point and all training points\n",
    "        distances = np.sum(np.abs(trainx - evalx[i]), axis=1)\n",
    "        \n",
    "        # Find the index of the nearest neighbor\n",
    "        nearest_neighbor_index = np.argmin(distances)\n",
    "        \n",
    "        # Assign the label of the nearest neighbor to the test point\n",
    "        predictions[i] = trainy[nearest_neighbor_index]\n",
    "    \n",
    "    return predictions#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L1**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification and L1 distance metric. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    predictions = []\n",
    "    \n",
    "    # Iterate over each point in evalx\n",
    "    for eval_point in evalx:\n",
    "        # Calculate the L1 (Manhattan) distance between the eval_point and all training points\n",
    "        distances = np.sum(np.abs(trainx - eval_point), axis=1)\n",
    "        \n",
    "        # Find the indices of the K nearest neighbors\n",
    "        nearest_neighbor_indices = np.argsort(distances)[:K]\n",
    "        \n",
    "        # Get the labels of the K nearest neighbors\n",
    "        nearest_neighbor_labels = trainy[nearest_neighbor_indices]\n",
    "        \n",
    "        # Predict the label by majority voting\n",
    "        prediction = np.bincount(nearest_neighbor_labels).argmax()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Convert predictions list to a numpy array and return\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), the value of **K** (integer), and a parameter for deciding the distance metric to be used (for example 1 for L1 and 2 for L2) and predicts labels for these test points using KNN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, metric=2):\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbor classifier\n",
    "\n",
    "    Parameters:\n",
    "    trainx (np.array): Training data features\n",
    "    trainy (np.array): Training data labels\n",
    "    evalx (np.array): Evaluation data features\n",
    "    K (int): Number of neighbors to consider\n",
    "    metric (int): Distance metric to use (1 for L1, 2 for L2)\n",
    "\n",
    "    Returns:\n",
    "    np.array: Predicted labels for evaluation data\n",
    "    \"\"\"\n",
    "    if metric not in [1, 2]:\n",
    "        raise ValueError(\"Invalid metric. Use 1 for L1 distance or 2 for L2 distance.\")\n",
    "\n",
    "    if metric == 1:\n",
    "        return KNN_L1(trainx, trainy, evalx, K)\n",
    "    else:  # metric == 2\n",
    "        return KNN_L2(trainx, trainy, evalx, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that allows you to select the hyper-parameters (distance measure and the value of K) by calling the KNN classifier with different values of K and either L1 or L2 distance measure. Make sure that you set the hyper-parameters using the validation set and not the test set. You need to systemtically try different values for K in conjunction with a distance measure and tabulate the results (you can do that be craeting a seperate cell and documenting in that cell) and note down the best hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 3\n",
      "Best Distance Metric: L1\n",
      "Best Validation Accuracy: 0.9882\n",
      "Test Accuracy for Best K and Distance Metric: 0.9535\n",
      "\n",
      "Results for all K and distance metrics combinations:\n",
      "K: 1, Distance Metric: L1, Validation Accuracy: 0.9765, Test Accuracy: 0.9419\n",
      "K: 1, Distance Metric: L2, Validation Accuracy: 0.9647, Test Accuracy: 0.9535\n",
      "K: 3, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9535\n",
      "K: 3, Distance Metric: L2, Validation Accuracy: 0.9765, Test Accuracy: 0.9651\n",
      "K: 5, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9651\n",
      "K: 5, Distance Metric: L2, Validation Accuracy: 0.9765, Test Accuracy: 0.9651\n",
      "K: 7, Distance Metric: L1, Validation Accuracy: 0.9765, Test Accuracy: 0.9651\n",
      "K: 7, Distance Metric: L2, Validation Accuracy: 0.9647, Test Accuracy: 0.9767\n",
      "K: 9, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9651\n",
      "K: 9, Distance Metric: L2, Validation Accuracy: 0.9765, Test Accuracy: 0.9651\n",
      "K: 11, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9535\n",
      "K: 11, Distance Metric: L2, Validation Accuracy: 0.9882, Test Accuracy: 0.9535\n",
      "K: 13, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9419\n",
      "K: 13, Distance Metric: L2, Validation Accuracy: 0.9882, Test Accuracy: 0.9535\n",
      "K: 15, Distance Metric: L1, Validation Accuracy: 0.9882, Test Accuracy: 0.9419\n",
      "K: 15, Distance Metric: L2, Validation Accuracy: 0.9882, Test Accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Define the range of K values to test\n",
    "k_values = range(1, 16, 2)  # Testing K values from 1 to 15, stepping by 2\n",
    "\n",
    "# Define the distance metrics to test\n",
    "distance_metrics = [1, 2]  # 1 for L1, 2 for L2\n",
    "\n",
    "# Variables to store the best hyper-parameters and their corresponding accuracy\n",
    "best_k = None\n",
    "best_dist_metric = None\n",
    "best_val_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "\n",
    "# Dictionary to store results for documentation\n",
    "results = {}\n",
    "\n",
    "# Iterate over all combinations of K and distance metrics\n",
    "for k in k_values:\n",
    "    for dist_metric in distance_metrics:\n",
    "        # Predict on the validation and test sets using the current combination of K and distance metric\n",
    "        val_predictions = KNN(X_train, y_train, X_val, k, dist_metric)\n",
    "        test_predictions = KNN(X_train, y_train, X_test, k, dist_metric)\n",
    "        \n",
    "        # Calculate the accuracy on the validation and test sets\n",
    "        val_accuracy = np.mean(y_val == val_predictions)\n",
    "        test_accuracy = np.mean(y_test == test_predictions)\n",
    "        \n",
    "        # Store the result\n",
    "        results[(k, dist_metric)] = (val_accuracy, test_accuracy)\n",
    "        \n",
    "        # Update best parameters if the current validation accuracy is better\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_test_accuracy = test_accuracy\n",
    "            best_k = k\n",
    "            best_dist_metric = dist_metric\n",
    "\n",
    "# Print the best hyper-parameters and their corresponding accuracies\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Distance Metric: {'L1' if best_dist_metric == 1 else 'L2'}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy for Best K and Distance Metric: {best_test_accuracy:.4f}\")\n",
    "\n",
    "# Print the tabulated results for reference\n",
    "print(\"\\nResults for all K and distance metrics combinations:\")\n",
    "for (k, dist_metric), (val_accuracy, test_accuracy) in results.items():\n",
    "    print(f\"K: {k}, Distance Metric: {'L1' if dist_metric == 1 else 'L2'}, Validation Accuracy: {val_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Define the range of K values to test\n",
    "k_values = range(1, 16,2)  # Testing K values from 1 to 20\n",
    "\n",
    "# Define the distance metrics to test\n",
    "distance_metrics = [1, 2]  # 1 for L1, 2 for L2\n",
    "\n",
    "# Variables to store the best hyper-parameters and their corresponding accuracy\n",
    "best_k = None\n",
    "best_dist_metric = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Dictionary to store results for documentation\n",
    "results = {}\n",
    "\n",
    "# Iterate over all combinations of K and distance metrics\n",
    "for k in k_values:\n",
    "    for dist_metric in distance_metrics:\n",
    "        # Predict on the validation set using the current combination of K and distance metric\n",
    "        val_predictions = KNN(X_train, y_train, X_val, k, dist_metric)\n",
    "        test_predictions = KNN(X_train, y_train, X_test, k, dist_metric)\n",
    "        # Calculate the accuracy on the validation set\n",
    "        val_accuracy = np.mean(y_val == val_predictions)\n",
    "        test_accuracy = np.mean(y_test == test_predictions)\n",
    "        \n",
    "        # Store the result\n",
    "        results[(k, dist_metric)] = val_accuracy\n",
    "        \n",
    "        # Update best parameters if the current accuracy is better\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_k = k\n",
    "            best_dist_metric = dist_metric\n",
    "\n",
    "# Print the best hyper-parameters and their corresponding accuracy\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Distance Metric: {'L1' if best_dist_metric == 1 else 'L2'}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Print the tabulated results for reference\n",
    "print(\"\\nResults for all K and distance metrics combinations:\")\n",
    "for (k, dist_metric), accuracy in results.items():\n",
    "    print(f\"K: {k}, Distance Metric: {'L1' if dist_metric == 1 else 'L2'}, Validation Accuracy: {accuracy:.4f}\")\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the hyper-parameters have been selected, we now would like to perform a final evaluation on the test set and record the error rates. Also, Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array`.\n",
    "\n",
    "**Note:** Record the cpu time it takes to perform the evaluation on the test set using functions like **time.time()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(testy, testy_fit):\n",
    "    # inputs: the correct labels, the fitted KNN labels \n",
    "    # output: a 10x10 np.array representing the confusion matrix\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize a 10x10 numpy array with zeros\n",
    "    conf_matrix = np.zeros((10, 10), dtype=int)\n",
    "    \n",
    "    # Populate the confusion matrix\n",
    "    for true, pred in zip(testy, testy_fit):\n",
    "        conf_matrix[true][pred] += 1\n",
    "    \n",
    "    return conf_matrix\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.0040 seconds\n",
      "Test Error Rate: 0.0465\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  3  0  0  0  0  0  0  0  0]\n",
      " [ 1 56  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Code for performing the final evaluation on the test set and generating the confuson matrix.\n",
    "### START CODE HERE ###\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "# Predict on the test set using the best K and distance metric\n",
    "test_predictions = KNN(X_train, y_train, X_test, best_k, best_dist_metric)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "evaluation_time = end_time - start_time  # Calculate evaluation time\n",
    "\n",
    "# Calculate the error rate\n",
    "error_rate = 1 - accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Evaluation Time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Test Error Rate: {error_rate:.4f}\")\n",
    "\n",
    "# Get the confusion matrix for the test set\n",
    "conf_matrix = confusion(y_test, test_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preparing the assignment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to record your answers for the following questions:\n",
    "1. What is the error rate on the validation set for NN_L2?\n",
    "2. What is the best error rate on the validation set for KNN_L2?\n",
    "3. What is the error rate on the validation set for NN_L1?\n",
    "4. What is the best error rate on the validation set for KNN_L1?\n",
    "5. What is the error rate on the test set?\n",
    "7. Do you need to normalize data, in general, when using KNN?\n",
    "8. Do you need to normalize data when using KNN for the given problem? Explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the error rate on the validation set for NN_L2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.0353\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(NN_L2(X_train, y_train, X_val) == y_val)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the best error rate on the validation set for KNN_L2?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as shown before, the best accuracy was at k = 3 and using L2 and the error rate is 1 - 0.9412 = 0.0588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the error rate on the validation set for NN_L1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.0235\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(NN_L1(X_train, y_train, X_val) == y_val)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.What is the best error rate on the validation set for KNN_L1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best K: 6\n",
    "Best Distance Metric: L1\n",
    "Best error rate: 1 - 0.9647 = 0.353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the error rate on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_L1 Error Rate: 0.0581\n",
      "NN_L2 Error Rate: 0.0465\n",
      "KNN_L1 Error Rate: 0.0349\n",
      "KNN_L2 Error Rate: 0.0349\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(NN_L1(X_train, y_train, X_test) == y_test)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"NN_L1 Error Rate: {error_rate:.4f}\")\n",
    "\n",
    "accuracy = np.mean(NN_L2(X_train, y_train, X_test) == y_test)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"NN_L2 Error Rate: {error_rate:.4f}\")\n",
    "\n",
    "\n",
    "accuracy = np.mean(KNN(X_train, y_train, X_test, 5, metric = 1)== y_test)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"KNN_L1 Error Rate: {error_rate:.4f}\")\n",
    "\n",
    "accuracy = np.mean(KNN(X_train, y_train, X_test, 11 , metric = 2) == y_test)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"KNN_L2 Error Rate: {error_rate:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do you need to normalize data, in general, when using KNN?\n",
    "\n",
    "It is better in general to normalize the data in knn for the following reasons:\n",
    "\n",
    "* KNN uses distance calculations between data points.\n",
    "* Features with larger scales can dominate the distance calculations.\n",
    "* Normalization ensures all features contribute equally to the distance metric.\n",
    "* It prevents features with larger numerical ranges from having undue influence on the results.\n",
    "\n",
    "but for one case maybe normalizing the dataset is not a good idea when we have for example two features and one of the features are in reality dominant and they should have big value, if we normalized them this will result in removing this needed dominance and will affect the performance negatively\n",
    "\n",
    "Normalizing data helps KNN perform more accurately and fairly across all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Do you need to normalize data when using KNN for the given problem? Explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes we need, as you can see below, we examined one sample for X and we can see the values are ranging with number with zero and fractions and numbers are in thousands, when we are going to measure the distance, the features with low values will be dominated with the features with high values. that is why we need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Implementing weighted KNN where the vote of a neighbour is scaled down based on its distance from the test point.\n",
    "2. Implement L_infinity distance measure and use it for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    # inputs: \n",
    "    # trainx (training features), \n",
    "    # trainy (training labels), \n",
    "    # evalx (evaluation features), \n",
    "    # K (number of neighbors), \n",
    "    # dist_metric (1 for L1, 2 for L2)\n",
    "    \n",
    "    predictions = np.empty(evalx.shape[0], dtype=int)\n",
    "    \n",
    "    if dist_metric == 1:\n",
    "        distances = np.sum(np.abs(trainx[np.newaxis, :] - evalx[:, np.newaxis]), axis=2)\n",
    "    elif dist_metric == 2:\n",
    "        distances = np.sqrt(np.sum((trainx[np.newaxis, :] - evalx[:, np.newaxis])**2, axis=2))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric! Use 1 for L1 and 2 for L2.\")\n",
    "    \n",
    "    for i in range(evalx.shape[0]):\n",
    "        # Find the indices of the K nearest neighbors\n",
    "        nearest_neighbor_idxs = np.argsort(distances[i])[:K]\n",
    "        \n",
    "        # Get the distances of the K nearest neighbors\n",
    "        nearest_distances = distances[i][nearest_neighbor_idxs]\n",
    "        \n",
    "        # Calculate the weights (inverse of the distances)\n",
    "        weights = 1 / (nearest_distances + 1e-5)  # Add a small value to avoid division by zero\n",
    "        \n",
    "        # Get the labels of the K nearest neighbors\n",
    "        nearest_labels = trainy[nearest_neighbor_idxs]\n",
    "        \n",
    "        # Calculate the weighted votes\n",
    "        unique_labels = np.unique(nearest_labels)\n",
    "        weighted_votes = np.zeros(len(unique_labels))\n",
    "        \n",
    "        for idx, label in enumerate(unique_labels):\n",
    "            label_weights = weights[nearest_labels == label]\n",
    "            weighted_votes[idx] = np.sum(label_weights)\n",
    "        \n",
    "        # Predict the label with the maximum weighted vote\n",
    "        predictions[i] = unique_labels[np.argmax(weighted_votes)]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for Weighted KNN (K=5, L2): 0.9412\n",
      "Validation Accuracy for Weighted KNN (K=5, L1): 0.9529\n"
     ]
    }
   ],
   "source": [
    "weighted_predictions = weighted_KNN(X_train, y_train, X_val, K=4, dist_metric=2)\n",
    "weighted_val_accuracy = accuracy_score(y_val, weighted_predictions)\n",
    "print(f\"Validation Accuracy for Weighted KNN (K=5, L2): {weighted_val_accuracy:.4f}\")\n",
    "\n",
    "# Test Weighted KNN with K=5 and L1 distance\n",
    "weighted_predictions_l1 = weighted_KNN(X_train, y_train, X_val, K=5, dist_metric=1)\n",
    "weighted_val_accuracy_l1 = accuracy_score(y_val, weighted_predictions_l1)\n",
    "print(f\"Validation Accuracy for Weighted KNN (K=5, L1): {weighted_val_accuracy_l1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Weighted KNN (K=5, L1): 0.9302\n",
      "\n",
      "Confusion Matrix for Test Set (Weighted KNN, K=5, L1):\n",
      "[[23  6  0  0  0  0  0  0  0  0]\n",
      " [ 0 57  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Assume the best model is Weighted KNN with K=5 and L2\n",
    "# Test on the test set\n",
    "weighted_test_predictions = weighted_KNN(X_train, y_train, X_test, K=5, dist_metric=1)\n",
    "weighted_test_accuracy = accuracy_score(y_test, weighted_test_predictions)\n",
    "print(f\"Test Accuracy for Weighted KNN (K=5, L1): {weighted_test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the test set\n",
    "conf_matrix_test = confusion(y_test, weighted_test_predictions)\n",
    "print(\"\\nConfusion Matrix for Test Set (Weighted KNN, K=5, L1):\")\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L_infinity(trainx, trainy, evalx, K):\n",
    "    # inputs: \n",
    "    # trainx (training features), \n",
    "    # trainy (training labels), \n",
    "    # evalx (evaluation features), \n",
    "    # K (number of neighbors)\n",
    "    \n",
    "    # Initialize an empty array to store the predictions\n",
    "    predictions = np.empty(evalx.shape[0], dtype=int)\n",
    "    \n",
    "    # Calculate L-infinity (Chebyshev) distance between each eval point and all train points\n",
    "    distances = np.max(np.abs(trainx[np.newaxis, :] - evalx[:, np.newaxis]), axis=2)\n",
    "    \n",
    "    # Find the indices of the K nearest neighbors for each evaluation point\n",
    "    nearest_neighbor_idxs = np.argsort(distances, axis=1)[:, :K]\n",
    "    \n",
    "    # Use fancy indexing to get the labels of the K nearest neighbors\n",
    "    nearest_neighbor_labels = trainy[nearest_neighbor_idxs]\n",
    "    \n",
    "    # For each evaluation point, find the most common label among the K neighbors using numpy functions\n",
    "    for i in range(evalx.shape[0]):\n",
    "        labels, counts = np.unique(nearest_neighbor_labels[i], return_counts=True)\n",
    "        most_common_label = labels[np.argmax(counts)]\n",
    "        predictions[i] = most_common_label\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for KNN with L-infinity (K=5): 0.9294\n"
     ]
    }
   ],
   "source": [
    "# Test L-infinity KNN with K=5\n",
    "linfinity_predictions = KNN_L_infinity(X_train, y_train, X_val, K=5)\n",
    "linfinity_val_accuracy = accuracy_score(y_val, linfinity_predictions)\n",
    "print(f\"Validation Accuracy for KNN with L-infinity (K=5): {linfinity_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for KNN with L-infinity (K=5): 0.9186\n",
      "\n",
      "Confusion Matrix for Test Set (KNN with L-infinity, K=5):\n",
      "[[24  5  0  0  0  0  0  0  0  0]\n",
      " [ 2 55  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "K_best = 5\n",
    "\n",
    "# Test KNN with L-infinity distance on the test set\n",
    "linfinity_test_predictions = KNN_L_infinity(X_train, y_train, X_test, K=K_best)\n",
    "linfinity_test_accuracy = accuracy_score(y_test, linfinity_test_predictions)\n",
    "print(f\"Test Accuracy for KNN with L-infinity (K={K_best}): {linfinity_test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the test set\n",
    "conf_matrix_test_linfinity = confusion(y_test, linfinity_test_predictions)\n",
    "print(\"\\nConfusion Matrix for Test Set (KNN with L-infinity, K=5):\")\n",
    "print(conf_matrix_test_linfinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. \n",
    "2. Vectorize the code wherever possible instead of using explicit loops. This will significantly speed-up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
