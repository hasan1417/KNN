{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)-Part-A\n",
    "## Handwritten digit recognition\n",
    "In this assignment part-A, we will use the built-in library ``sklearn`` to use KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "`MNIST` is a classic dataset in machine learning, consisting of 28x28 gray-scale images handwritten digits. The training set contains 60,000 examples and the test set contains 10,000 examples. In this assignment we will further split the training set to take out 12,000 examples as a validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions:  (60000, 784)\n",
      "Number of training labels:  60000\n",
      "Testing dataset dimensions:  (10000, 784)\n",
      "Number of testing labels:  10000\n"
     ]
    }
   ],
   "source": [
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test set distribution:\n",
      "{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "## Compute the number of examples of each digit\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Training set distribution:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test set distribution:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7\n"
     ]
    }
   ],
   "source": [
    "## Define a function that displays a digit given its vector representation\n",
    "def show_digit(x):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "## Define a function that takes an index into a particular data set (\"train\" or \"test\") and displays that image.\n",
    "def vis_image(index, dataset=\"train\"):\n",
    "    if(dataset==\"train\"): \n",
    "        show_digit(train_data[index,])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index,])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label \" + str(label))\n",
    "    return\n",
    "\n",
    "## View the first data point in the training set\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Now view the first data point in the test set\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, valx, trainy, valy = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest neighbor classifier--Brute Force Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in KNN classifier to perform handwritten digit classification task. Please keep in mind that any hyper-parameter selection shall be performed on the independent validation set and not on the test set. You need to study the KNeighborsClassifier documentation to understand how to use the api with different parameters. In this set of experiments, you need to select 'brute' for the **algorithm** parameter. Record the error rates on the test set and the cpu time taken for evaluation.\n",
    "\n",
    "**Note:** Here you don't have to implement the KNN classifier but you just need to use it from ``sklearn`` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, Validation Accuracy: 0.9741\n",
      "k=3, Validation Accuracy: 0.9727\n",
      "k=5, Validation Accuracy: 0.9715\n",
      "k=7, Validation Accuracy: 0.9696\n",
      "k=9, Validation Accuracy: 0.9673\n",
      "\n",
      "Best k: 1\n",
      "\n",
      "Test Error Rate: 0.0327\n",
      "CPU Time for Evaluation: 8.9578 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "### START CODE HERE ###\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Function to train and evaluate KNN model\n",
    "def train_evaluate_knn(k, X_train, y_train, X_val, y_val):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_predictions = knn.predict(X_val)\n",
    "    return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# List of k values to try\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Find the best k using validation set\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_values:\n",
    "    accuracy = train_evaluate_knn(k, trainx, trainy, valx, valy)\n",
    "    print(f\"k={k}, Validation Accuracy: {accuracy:.4f}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"\\nBest k: {best_k}\")\n",
    "\n",
    "# Train the final model with the best k\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k, algorithm='brute')\n",
    "best_knn.fit(trainx, trainy)\n",
    "\n",
    "# Evaluate on test set\n",
    "start_time = time.time()\n",
    "test_predictions = best_knn.predict(test_data)\n",
    "end_time = time.time()\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "cpu_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTest Error Rate: {test_error_rate:.4f}\")\n",
    "print(f\"CPU Time for Evaluation: {cpu_time:.4f} seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Faster nearest neighbor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\n",
    "\n",
    "Fortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data structures: the _ball tree_ and the _k-d tree_. Record the error rates on the test set and the cpu time taken for evaluation using these two faster methods.\n",
    "\n",
    "**Note:** You need to select 'ball_tree'or 'kd_tree' for the **algorithm** parameter for ``KNeighborsClassifier`` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: brute\n",
      "Error Rate: 0.0312\n",
      "Training Time: 0.0032 seconds\n",
      "\n",
      "Algorithm: ball_tree\n",
      "Error Rate: 0.0312\n",
      "Training Time: 17.6852 seconds\n",
      "\n",
      "Algorithm: kd_tree\n",
      "Error Rate: 0.0312\n",
      "Training Time: 23.6659 seconds\n"
     ]
    }
   ],
   "source": [
    "# You can use KNeighborsClassifier with correct values for 'algorithm'\n",
    "### START CODE HERE ###\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Function to evaluate KNN with different algorithms\n",
    "def evaluate_knn(algorithm, X_train, y_train, X_test, y_test, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm)\n",
    "    \n",
    "    # Training time\n",
    "    train_start = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_time = time.time() - train_start\n",
    "    \n",
    "    # Testing time\n",
    "    test_start = time.time()\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    test_time = time.time() - test_start\n",
    "    \n",
    "    # Calculate error rate\n",
    "    error_rate = 1 - accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    return error_rate, train_time, test_time\n",
    "\n",
    "# List of algorithms to try\n",
    "algorithms = ['brute', 'ball_tree', 'kd_tree']\n",
    "k = 5  # You can adjust this value based on your previous findings\n",
    "\n",
    "# Evaluate each algorithm\n",
    "for alg in algorithms:\n",
    "    error_rate, train_time, test_time = evaluate_knn(alg, train_data, train_labels, test_data, test_labels, k)\n",
    "    print(f\"\\nAlgorithm: {alg}\")\n",
    "    print(f\"Error Rate: {error_rate:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.4f} seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Record CPU time and accuracy for all the three approaches in different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use brute-force, kd-tree, and ball-tree approaches for the following datasets and record the accuracies and cpu time (for evaluation step only). Looking at the results, can you explain it.\n",
    "\n",
    "Datasets:\n",
    "1. Abalone Data Set (https://archive.ics.uci.edu/ml/datasets/abalone)\n",
    "2. Statlog (Landsat Satellite) Data Set (https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite))\n",
    "\n",
    "**Note:** The datasets are provided as attachement in the assignment as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dataset  Algorithm  Accuracy  Evaluation Time\n",
      "0    Abalone      brute  0.226077         0.073206\n",
      "1    Abalone    kd_tree  0.226077         0.020559\n",
      "2    Abalone  ball_tree  0.226077         0.025656\n",
      "3  Satellite      brute  0.912908         0.117715\n",
      "4  Satellite    kd_tree  0.912908         0.142253\n",
      "5  Satellite  ball_tree  0.912908         0.130483\n",
      "\n",
      "Analysis for Abalone dataset:\n",
      "Fastest algorithm: kd_tree (Time: 0.0206s)\n",
      "Most accurate algorithm: brute (Accuracy: 0.2261)\n",
      "\n",
      "Analysis for Satellite dataset:\n",
      "Fastest algorithm: brute (Time: 0.1177s)\n",
      "Most accurate algorithm: brute (Accuracy: 0.9129)\n"
     ]
    }
   ],
   "source": [
    "# You can use KNeighborsClassifier with correct values for 'algorithm'\n",
    "### START CODE HERE ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def load_and_preprocess_data(file_path, column_names, target_column):\n",
    "    # Load the data with provided column names\n",
    "    data = pd.read_csv(file_path, names=column_names)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.drop(target_column, axis=1)\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    for column in X.select_dtypes(include=['object']):\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def evaluate_knn(X_train, X_test, y_train, y_test, algorithm, k=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Measure evaluation time\n",
    "    start_time = time.time()\n",
    "    y_pred = knn.predict(X_test)\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, eval_time\n",
    "\n",
    "# Load and preprocess datasets\n",
    "abalone_columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', \n",
    "                   'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "satellite_columns = [f'band_{i}' for i in range(1, 37)] + ['Class']\n",
    "\n",
    "# Load and preprocess datasets\n",
    "abalone_X, abalone_y = load_and_preprocess_data('abalone19.csv', abalone_columns, 'Rings')\n",
    "satellite_X, satellite_y = load_and_preprocess_data('186_satimage.csv', satellite_columns, 'Class')\n",
    "\n",
    "datasets = [\n",
    "    (\"Abalone\", abalone_X, abalone_y),\n",
    "    (\"Satellite\", satellite_X, satellite_y)\n",
    "]\n",
    "\n",
    "algorithms = ['brute', 'kd_tree', 'ball_tree']\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name, X, y in datasets:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        accuracy, eval_time = evaluate_knn(X_train, X_test, y_train, y_test, algorithm)\n",
    "        results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Algorithm': algorithm,\n",
    "            'Accuracy': accuracy,\n",
    "            'Evaluation Time': eval_time\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Analyze results\n",
    "for dataset in ['Abalone', 'Satellite']:\n",
    "    print(f\"\\nAnalysis for {dataset} dataset:\")\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
    "    fastest_algo = dataset_results.loc[dataset_results['Evaluation Time'].idxmin()]\n",
    "    most_accurate_algo = dataset_results.loc[dataset_results['Accuracy'].idxmax()]\n",
    "    \n",
    "    print(f\"Fastest algorithm: {fastest_algo['Algorithm']} (Time: {fastest_algo['Evaluation Time']:.4f}s)\")\n",
    "    print(f\"Most accurate algorithm: {most_accurate_algo['Algorithm']} (Accuracy: {most_accurate_algo['Accuracy']:.4f})\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E1. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Instead of using the pixels as features, implement your own features (example: what were presented in the slides) and use them for KNN. You need to keep in mind that if you compute features which have different scales then it is important to scale/normalize the features (discussed in the slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with custom features:\n",
      "Algorithm: brute\n",
      "Accuracy: 0.5375\n",
      "Evaluation Time: 8.3141 seconds\n",
      "\n",
      "Algorithm: kd_tree\n",
      "Accuracy: 0.5375\n",
      "Evaluation Time: 0.7418 seconds\n",
      "\n",
      "Algorithm: ball_tree\n",
      "Accuracy: 0.5375\n",
      "Evaluation Time: 2.4309 seconds\n",
      "\n",
      "Results with original pixels:\n",
      "Accuracy: 0.9715\n",
      "Evaluation Time: 613.7484 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        img = image.reshape(28, 28)\n",
    "        \n",
    "        # Feature 1: Mean intensity\n",
    "        mean_intensity = np.mean(img)\n",
    "        \n",
    "        # Feature 2: Standard deviation of intensity\n",
    "        std_intensity = np.std(img)\n",
    "        \n",
    "        # Feature 3: Horizontal symmetry\n",
    "        h_symmetry = np.mean(np.abs(img[:, :14] - np.fliplr(img[:, 14:])))\n",
    "        \n",
    "        # Feature 4: Vertical symmetry\n",
    "        v_symmetry = np.mean(np.abs(img[:14, :] - np.flipud(img[14:, :])))\n",
    "        \n",
    "        # Feature 5: Number of pixels above mean intensity\n",
    "        above_mean = np.sum(img > mean_intensity) / img.size\n",
    "        \n",
    "        # Feature 6: Ratio of non-zero pixels\n",
    "        non_zero_ratio = np.count_nonzero(img) / img.size\n",
    "        \n",
    "        # Feature 7-10: Intensity of four quadrants\n",
    "        quadrants = [img[:14, :14], img[:14, 14:], img[14:, :14], img[14:, 14:]]\n",
    "        quadrant_intensities = [np.mean(q) for q in quadrants]\n",
    "        \n",
    "        features.append([mean_intensity, std_intensity, h_symmetry, v_symmetry, \n",
    "                         above_mean, non_zero_ratio] + quadrant_intensities)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def evaluate_knn(X_train, X_test, y_train, y_test, algorithm, k=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Measure evaluation time\n",
    "    start_time = time.time()\n",
    "    y_pred = knn.predict(X_test)\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, eval_time\n",
    "\n",
    "# Extract features from the MNIST dataset\n",
    "X_features = extract_features(train_data)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "algorithms = ['brute', 'kd_tree', 'ball_tree']\n",
    "results = []\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    accuracy, eval_time = evaluate_knn(X_train, X_test, y_train, y_test, algorithm)\n",
    "    results.append({\n",
    "        'Algorithm': algorithm,\n",
    "        'Accuracy': accuracy,\n",
    "        'Evaluation Time': eval_time\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"Results with custom features:\")\n",
    "for result in results:\n",
    "    print(f\"Algorithm: {result['Algorithm']}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Evaluation Time: {result['Evaluation Time']:.4f} seconds\")\n",
    "    print()\n",
    "\n",
    "# Compare with original pixel-based approach\n",
    "X_pixel_train, X_pixel_test, y_pixel_train, y_pixel_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "pixel_accuracy, pixel_eval_time = evaluate_knn(X_pixel_train, X_pixel_test, y_pixel_train, y_pixel_test, 'kd_tree')\n",
    "\n",
    "print(\"Results with original pixels:\")\n",
    "print(f\"Accuracy: {pixel_accuracy:.4f}\")\n",
    "print(f\"Evaluation Time: {pixel_eval_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
