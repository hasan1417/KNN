{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)-Part-A\n",
    "## Handwritten digit recognition\n",
    "In this assignment part-A, we will use the built-in library ``sklearn`` to use KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "`MNIST` is a classic dataset in machine learning, consisting of 28x28 gray-scale images handwritten digits. The training set contains 60,000 examples and the test set contains 10,000 examples. In this assignment we will further split the training set to take out 12,000 examples as a validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from urllib.request import urlretrieve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions:  (60000, 784)\n",
      "Number of training labels:  60000\n",
      "Testing dataset dimensions:  (10000, 784)\n",
      "Number of testing labels:  10000\n"
     ]
    }
   ],
   "source": [
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "{np.uint8(0): np.int64(5923), np.uint8(1): np.int64(6742), np.uint8(2): np.int64(5958), np.uint8(3): np.int64(6131), np.uint8(4): np.int64(5842), np.uint8(5): np.int64(5421), np.uint8(6): np.int64(5918), np.uint8(7): np.int64(6265), np.uint8(8): np.int64(5851), np.uint8(9): np.int64(5949)}\n",
      "Test set distribution:\n",
      "{np.uint8(0): np.int64(980), np.uint8(1): np.int64(1135), np.uint8(2): np.int64(1032), np.uint8(3): np.int64(1010), np.uint8(4): np.int64(982), np.uint8(5): np.int64(892), np.uint8(6): np.int64(958), np.uint8(7): np.int64(1028), np.uint8(8): np.int64(974), np.uint8(9): np.int64(1009)}\n"
     ]
    }
   ],
   "source": [
    "## Compute the number of examples of each digit\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Training set distribution:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test set distribution:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7\n"
     ]
    }
   ],
   "source": [
    "## Define a function that displays a digit given its vector representation\n",
    "def show_digit(x):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "## Define a function that takes an index into a particular data set (\"train\" or \"test\") and displays that image.\n",
    "def vis_image(index, dataset=\"train\"):\n",
    "    if(dataset==\"train\"): \n",
    "        show_digit(train_data[index,])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index,])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label \" + str(label))\n",
    "    return\n",
    "\n",
    "## View the first data point in the training set\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Now view the first data point in the test set\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, valx, trainy, valy = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler= StandardScaler()\n",
    "\n",
    "trainx = scaler.fit_transform(trainx)\n",
    "test_data = scaler.fit_transform(test_data)\n",
    "valx= scaler.fit_transform(valx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest neighbor classifier--Brute Force Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in KNN classifier to perform handwritten digit classification task. Please keep in mind that any hyper-parameter selection shall be performed on the independent validation set and not on the test set. You need to study the KNeighborsClassifier documentation to understand how to use the api with different parameters. In this set of experiments, you need to select 'brute' for the **algorithm** parameter. Record the error rates on the test set and the cpu time taken for evaluation.\n",
    "\n",
    "**Note:** Here you don't have to implement the KNN classifier but you just need to use it from ``sklearn`` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, Validation Accuracy: 0.9458\n",
      "k=3, Validation Accuracy: 0.9460\n",
      "k=5, Validation Accuracy: 0.9453\n",
      "k=7, Validation Accuracy: 0.9421\n",
      "k=9, Validation Accuracy: 0.9400\n",
      "k=11, Validation Accuracy: 0.9372\n",
      "\n",
      "Best k: 3\n",
      "\n",
      "Test Error Rate: 0.0577\n",
      "CPU Time for Inference: 3.0484 seconds\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Function to train and evaluate KNN model\n",
    "def train_evaluate_knn(k, X_train, y_train, X_val, y_val):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_predictions = knn.predict(X_val)\n",
    "    return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# List of k values to try\n",
    "k_values = [1 ,3, 5, 7, 9, 11]\n",
    "\n",
    "\n",
    "# Find the best k using validation set (model calibration)\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_values:\n",
    "    accuracy = train_evaluate_knn(k, trainx, trainy, valx, valy)\n",
    "    print(f\"k={k}, Validation Accuracy: {accuracy:.4f}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"\\nBest k: {best_k}\")\n",
    "\n",
    "# Train the final model with the best k\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k, algorithm='brute')\n",
    "best_knn.fit(trainx, trainy)\n",
    "\n",
    "# Evaluate on test set\n",
    "start_time = time.time()\n",
    "test_predictions = best_knn.predict(test_data)\n",
    "end_time = time.time()\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "cpu_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTest Error Rate: {test_error_rate:.4f}\")\n",
    "print(f\"CPU Time for Inference: {cpu_time:.4f} seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Faster nearest neighbor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\n",
    "\n",
    "Fortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data structures: the _ball tree_ and the _k-d tree_. Record the error rates on the test set and the cpu time taken for evaluation using these two faster methods.\n",
    "\n",
    "**Note:** You need to select 'ball_tree'or 'kd_tree' for the **algorithm** parameter for ``KNeighborsClassifier`` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: ball_tree\n",
      "Accuracy: 0.9423\n",
      "Inference Time: 3.7587 seconds\n",
      "Testing Time: 399.3969 seconds\n",
      "\n",
      "Algorithm: kd_tree\n",
      "Accuracy: 0.9423\n",
      "Inference Time: 5.0498 seconds\n",
      "Testing Time: 623.8043 seconds\n"
     ]
    }
   ],
   "source": [
    "# You can use KNeighborsClassifier with correct values for 'algorithm'\n",
    "### START CODE HERE ###\n",
    "# Function to evaluate KNN with different algorithms\n",
    "def evaluate_knn(algorithm, X_train, y_train, X_test, y_test, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm)\n",
    "    \n",
    "    # Training time\n",
    "    train_start = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_time = time.time() - train_start\n",
    "    \n",
    "    # Testing time\n",
    "    test_start = time.time()\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    test_time = time.time() - test_start\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    return accuracy, train_time, test_time\n",
    "\n",
    "# List of algorithms to try\n",
    "algorithms = ['ball_tree', 'kd_tree']\n",
    "k = 3\n",
    "\n",
    "\n",
    "# Evaluate each algorithm\n",
    "for alg in algorithms:\n",
    "    accuracy, train_time, test_time = evaluate_knn(alg, trainx, trainy, test_data, test_labels, k)\n",
    "    print(f\"\\nAlgorithm: {alg}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Inference Time: {train_time:.4f} seconds\")\n",
    "    print(f\"Testing Time: {test_time:.4f} seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Record CPU time and accuracy for all the three approaches in different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use brute-force, kd-tree, and ball-tree approaches for the following datasets and record the accuracies and cpu time (for evaluation step only). Looking at the results, can you explain it.\n",
    "\n",
    "Datasets:\n",
    "1. Abalone Data Set (https://archive.ics.uci.edu/ml/datasets/abalone)\n",
    "2. Statlog (Landsat Satellite) Data Set (https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite))\n",
    "\n",
    "**Note:** The datasets are provided as attachement in the assignment as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:06:39.903936Z",
     "iopub.status.busy": "2024-10-03T16:06:39.903430Z",
     "iopub.status.idle": "2024-10-03T16:06:40.711184Z",
     "shell.execute_reply": "2024-10-03T16:06:40.710015Z",
     "shell.execute_reply.started": "2024-10-03T16:06:39.903894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms: brute\n",
      "Validation Accuracy: 0.2919\n",
      "Test Accuracy: 0.2791\n",
      "CPU Time: 0.0520s\n",
      "\n",
      "Algorithms: kd_tree\n",
      "Validation Accuracy: 0.2919\n",
      "Test Accuracy: 0.2791\n",
      "CPU Time: 0.0508s\n",
      "\n",
      "Algorithms: ball_tree\n",
      "Validation Accuracy: 0.2919\n",
      "Test Accuracy: 0.2791\n",
      "CPU Time: 0.0587s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = np.genfromtxt('/kaggle/input/dataset/Abalone19.csv', delimiter = ',')\n",
    "data = data[:,1:]\n",
    "X=data[:,:-1]\n",
    "y=data[:,-1]\n",
    "y = y.astype(np.int64)\n",
    "trainx, tempx, trainy, tempy = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "valx, testx, valy, testy = train_test_split(tempx, tempy, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trainx = scaler.fit_transform(trainx)\n",
    "valx = scaler.fit_transform(valx)\n",
    "testx = scaler.fit_transform(testx)\n",
    "\n",
    "algorithms = ['brute', 'kd_tree', 'ball_tree']\n",
    "\n",
    "k_values = [29,31,33,35,37,39,41,43]\n",
    "\n",
    "best_k = 0\n",
    "val_acc = 0\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    knn.fit(trainx, trainy)\n",
    "    y_pred = knn.predict(valx)\n",
    "    acc = accuracy_score(y_pred,valy)\n",
    "    if acc  > val_acc:\n",
    "        best_k = k\n",
    "        val_acc = acc\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, algorithm=algorithm)\n",
    "    knn.fit(trainx, trainy)\n",
    "    start_time = time.time()\n",
    "    y_pred_test = knn.predict(testx)\n",
    "    end_time = time.time()\n",
    "    acc_test = accuracy_score(y_pred_test,testy)\n",
    "    print(f'Algorithms: {algorithm}')\n",
    "    print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "    print(f'Test Accuracy: {acc_test:.4f}')\n",
    "    print(f'CPU Time: {end_time - start_time:.4f}s\\n')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:10:56.812456Z",
     "iopub.status.busy": "2024-10-03T16:10:56.812000Z",
     "iopub.status.idle": "2024-10-03T16:10:58.113025Z",
     "shell.execute_reply": "2024-10-03T16:10:58.111667Z",
     "shell.execute_reply.started": "2024-10-03T16:10:56.812414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k 7\n",
      "Algorithms: brute\n",
      "Validation Accuracy: 0.9098\n",
      "Test Accuracy: 0.9098\n",
      "CPU Time: 0.0777s\n",
      "\n",
      "Algorithms: kd_tree\n",
      "Validation Accuracy: 0.9098\n",
      "Test Accuracy: 0.9098\n",
      "CPU Time: 0.1889s\n",
      "\n",
      "Algorithms: ball_tree\n",
      "Validation Accuracy: 0.9098\n",
      "Test Accuracy: 0.9098\n",
      "CPU Time: 0.1877s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = np.genfromtxt('/kaggle/input/dataset/186_satimage.csv', delimiter = ',')\n",
    "X=data[:,:-1]\n",
    "y=data[:,-1]\n",
    "y = y.astype(np.int64)\n",
    "trainx, tempx, trainy, tempy = train_test_split(X, y, test_size=0.30, random_state=45)\n",
    "valx, testx, valy, testy = train_test_split(tempx, tempy, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trainx = scaler.fit_transform(trainx)\n",
    "valx = scaler.fit_transform(valx)\n",
    "testx = scaler.fit_transform(testx)\n",
    "\n",
    "algorithms = ['brute', 'kd_tree', 'ball_tree']\n",
    "\n",
    "k_values = [1,3,5,7,9,11,13]\n",
    "\n",
    "best_k = 0\n",
    "val_acc = 0\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    knn.fit(trainx, trainy)\n",
    "    y_pred = knn.predict(valx)\n",
    "    acc = accuracy_score(y_pred,valy)\n",
    "    if acc  > val_acc:\n",
    "        best_k = k\n",
    "        val_acc = acc\n",
    "        \n",
    "print(f'best k {best_k}')\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, algorithm=algorithm)\n",
    "    knn.fit(trainx, trainy)\n",
    "    start_time = time.time()\n",
    "    y_pred_test = knn.predict(testx)\n",
    "    end_time = time.time()\n",
    "    acc_test = accuracy_score(y_pred_test,testy)\n",
    "    print(f'Algorithms: {algorithm}')\n",
    "    print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "    print(f'Test Accuracy: {acc_test:.4f}')\n",
    "    print(f'CPU Time: {end_time - start_time:.4f}s\\n')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E1. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Instead of using the pixels as features, implement your own features (example: what were presented in the slides) and use them for KNN. You need to keep in mind that if you compute features which have different scales then it is important to scale/normalize the features (discussed in the slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k for flattened image: 3, Validation Accuracy: 0.9460\n",
      "Test Accuracy for Flattened Image: 0.9423\n",
      "CPU Time for Flattened Image: 3.7090s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train_flattened = trainx.reshape(trainx.shape[0], -1)\n",
    "X_val_flattened = valx.reshape(valx.shape[0], -1)\n",
    "X_test_flattened = test_data.reshape(test_data.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25]\n",
    "\n",
    "# Variables to store the best k and accuracy\n",
    "best_k = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    knn.fit(X_train_flattened_scaled, trainy)\n",
    "    \n",
    "    y_pred_val = knn.predict(X_val_flattened_scaled)\n",
    "    val_acc = accuracy_score(y_pred_val, valy)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_k = k\n",
    "\n",
    "print(f'Best k for flattened image: {best_k}, Validation Accuracy: {best_val_acc:.4f}')\n",
    "\n",
    "# Step 5: Evaluate on the test set using the best k\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k, algorithm='brute')\n",
    "knn.fit(X_train_flattened_scaled, trainy)\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_test = knn.predict(X_test_flattened_scaled)\n",
    "end_time = time.time()\n",
    "\n",
    "test_acc = accuracy_score(y_pred_test, test_labels)\n",
    "print(f'Test Accuracy for Flattened Image: {test_acc:.4f}')\n",
    "print(f'CPU Time for Flattened Image: {end_time - start_time:.4f}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5806184,
     "sourceId": 9533409,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5812086,
     "sourceId": 9541045,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
